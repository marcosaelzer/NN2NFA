# Generated from ToyNNet.g4 by ANTLR 4.10.1
from antlr4 import *
from io import StringIO
import sys
if sys.version_info[1] > 5:
    from typing import TextIO
else:
    from typing.io import TextIO


def serializedATN():
    return [
        4,0,14,128,6,-1,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,5,
        2,6,7,6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,2,12,7,12,2,
        13,7,13,2,14,7,14,2,15,7,15,2,16,7,16,2,17,7,17,2,18,7,18,2,19,7,
        19,2,20,7,20,1,0,1,0,1,1,1,1,1,2,1,2,1,3,1,3,1,4,1,4,1,5,1,5,1,6,
        1,6,1,7,1,7,1,8,1,8,1,9,1,9,1,10,1,10,1,11,1,11,1,12,1,12,1,13,1,
        13,1,14,3,14,73,8,14,1,14,4,14,76,8,14,11,14,12,14,77,1,14,1,14,
        4,14,82,8,14,11,14,12,14,83,3,14,86,8,14,1,15,1,15,1,15,1,15,1,15,
        1,16,1,16,1,16,1,17,1,17,1,17,1,17,1,17,1,17,1,17,1,17,1,17,1,17,
        1,17,1,18,1,18,5,18,109,8,18,10,18,12,18,112,9,18,1,18,1,18,3,18,
        116,8,18,1,18,1,18,1,19,1,19,1,19,1,19,1,20,1,20,1,20,3,20,127,8,
        20,0,0,21,1,1,3,2,5,3,7,4,9,5,11,6,13,7,15,0,17,0,19,0,21,0,23,0,
        25,0,27,0,29,8,31,9,33,10,35,11,37,12,39,13,41,14,1,0,9,2,0,82,82,
        114,114,2,0,69,69,101,101,2,0,76,76,108,108,2,0,85,85,117,117,2,
        0,73,73,105,105,2,0,68,68,100,100,1,0,48,57,2,0,10,10,13,13,2,0,
        9,9,32,32,127,0,1,1,0,0,0,0,3,1,0,0,0,0,5,1,0,0,0,0,7,1,0,0,0,0,
        9,1,0,0,0,0,11,1,0,0,0,0,13,1,0,0,0,0,29,1,0,0,0,0,31,1,0,0,0,0,
        33,1,0,0,0,0,35,1,0,0,0,0,37,1,0,0,0,0,39,1,0,0,0,0,41,1,0,0,0,1,
        43,1,0,0,0,3,45,1,0,0,0,5,47,1,0,0,0,7,49,1,0,0,0,9,51,1,0,0,0,11,
        53,1,0,0,0,13,55,1,0,0,0,15,57,1,0,0,0,17,59,1,0,0,0,19,61,1,0,0,
        0,21,63,1,0,0,0,23,65,1,0,0,0,25,67,1,0,0,0,27,69,1,0,0,0,29,72,
        1,0,0,0,31,87,1,0,0,0,33,92,1,0,0,0,35,95,1,0,0,0,37,106,1,0,0,0,
        39,119,1,0,0,0,41,126,1,0,0,0,43,44,5,61,0,0,44,2,1,0,0,0,45,46,
        5,59,0,0,46,4,1,0,0,0,47,48,5,40,0,0,48,6,1,0,0,0,49,50,5,44,0,0,
        50,8,1,0,0,0,51,52,5,41,0,0,52,10,1,0,0,0,53,54,5,91,0,0,54,12,1,
        0,0,0,55,56,5,93,0,0,56,14,1,0,0,0,57,58,7,0,0,0,58,16,1,0,0,0,59,
        60,7,1,0,0,60,18,1,0,0,0,61,62,7,2,0,0,62,20,1,0,0,0,63,64,7,3,0,
        0,64,22,1,0,0,0,65,66,7,4,0,0,66,24,1,0,0,0,67,68,7,5,0,0,68,26,
        1,0,0,0,69,70,7,6,0,0,70,28,1,0,0,0,71,73,5,45,0,0,72,71,1,0,0,0,
        72,73,1,0,0,0,73,75,1,0,0,0,74,76,3,27,13,0,75,74,1,0,0,0,76,77,
        1,0,0,0,77,75,1,0,0,0,77,78,1,0,0,0,78,85,1,0,0,0,79,81,5,46,0,0,
        80,82,3,27,13,0,81,80,1,0,0,0,82,83,1,0,0,0,83,81,1,0,0,0,83,84,
        1,0,0,0,84,86,1,0,0,0,85,79,1,0,0,0,85,86,1,0,0,0,86,30,1,0,0,0,
        87,88,3,15,7,0,88,89,3,17,8,0,89,90,3,19,9,0,90,91,3,21,10,0,91,
        32,1,0,0,0,92,93,3,23,11,0,93,94,3,25,12,0,94,34,1,0,0,0,95,96,5,
        105,0,0,96,97,5,110,0,0,97,98,5,112,0,0,98,99,5,117,0,0,99,100,5,
        116,0,0,100,101,5,95,0,0,101,102,5,115,0,0,102,103,5,105,0,0,103,
        104,5,122,0,0,104,105,5,101,0,0,105,36,1,0,0,0,106,110,5,35,0,0,
        107,109,8,7,0,0,108,107,1,0,0,0,109,112,1,0,0,0,110,108,1,0,0,0,
        110,111,1,0,0,0,111,115,1,0,0,0,112,110,1,0,0,0,113,116,3,41,20,
        0,114,116,5,0,0,1,115,113,1,0,0,0,115,114,1,0,0,0,116,117,1,0,0,
        0,117,118,6,18,0,0,118,38,1,0,0,0,119,120,7,8,0,0,120,121,1,0,0,
        0,121,122,6,19,0,0,122,40,1,0,0,0,123,124,5,13,0,0,124,127,5,10,
        0,0,125,127,7,7,0,0,126,123,1,0,0,0,126,125,1,0,0,0,127,42,1,0,0,
        0,8,0,72,77,83,85,110,115,126,1,6,0,0
    ]

class ToyNNetLexer(Lexer):

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    T__0 = 1
    T__1 = 2
    T__2 = 3
    T__3 = 4
    T__4 = 5
    T__5 = 6
    T__6 = 7
    NUMBER = 8
    RELU = 9
    ID = 10
    INPUTKEY = 11
    COMMENT = 12
    WHITESPACE = 13
    NEWLINE = 14

    channelNames = [ u"DEFAULT_TOKEN_CHANNEL", u"HIDDEN" ]

    modeNames = [ "DEFAULT_MODE" ]

    literalNames = [ "<INVALID>",
            "'='", "';'", "'('", "','", "')'", "'['", "']'", "'input_size'" ]

    symbolicNames = [ "<INVALID>",
            "NUMBER", "RELU", "ID", "INPUTKEY", "COMMENT", "WHITESPACE", 
            "NEWLINE" ]

    ruleNames = [ "T__0", "T__1", "T__2", "T__3", "T__4", "T__5", "T__6", 
                  "R", "E", "L", "U", "I", "D", "DIGIT", "NUMBER", "RELU", 
                  "ID", "INPUTKEY", "COMMENT", "WHITESPACE", "NEWLINE" ]

    grammarFileName = "ToyNNet.g4"

    def __init__(self, input=None, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.10.1")
        self._interp = LexerATNSimulator(self, self.atn, self.decisionsToDFA, PredictionContextCache())
        self._actions = None
        self._predicates = None


